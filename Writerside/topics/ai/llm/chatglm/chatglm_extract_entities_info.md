# ChatGLM2 实体抽取

<show-structure depth="2" />

我们已经通过实践证明了 ChatGLM 在文本分类上的效果非常好，在 ChatGLM 的官方 Github 上也有信息抽取的案例，但是案例也比较简单，对于解决实际业务需求还有很大的差距。


## 1. GLM仓库的信息抽取示例


```Text
2022年11月4日，计算机系通过线上线下相结合的方式在东主楼10-103会议室召开博士研究生导师交流会。计算机学科学位分委员会主席孙茂松，计算机系副主任武永卫、党委副书记韩文弢出席会议，博士生研究生导师和教学办工作人员等30余人参加会议，会议由武永卫主持。

提取“人”(name, position)，“时间”，“事件”，“地点”类型的实体．并输出为JSON格式
```

针对上述新闻的文本内容，通过设定 Prompt 来让 ChatGLM 提取出该段新闻中关于**人、时间、地点、事件**等具体信息，并将输出结果以 JSON 格式进行保存，以下是输出结果的示例:

```json
{
  "人": [
    {"name": "孙茂松", "position": "主席"},
    {"name": "武永卫", "position": "副主任"},
    {"name": "韩文弢", "position": "党委副书记"},
    {"name": "博士生研究生导师", "position":"其他"},
    {"name": "教学办工作人员", "position": "其他"}
  ],
  "时间": "20221104",
  "事件": "博士研究生导师交流会",
  "地点": "东主楼10-103会议室"
}
```

可以看到的是，绝大部分信息的抽取是正确的，但也有一些少量的实体信息提取错误，整体来说对于常见的实体信息抽取的表现还是非常不错的。

> 将此方法迁移到我们实际业务中，**发现实际效果并不是很好**，主要原因在于所使用的基座大模型可能在训练时已经专门优化过对于*人、时间、事件、地点*这样的实体抽取，但是实际业务问题往往偏向于专业领域，大模型没有见过这样的语料信息，提取信息的内容有误是也很正常的。

## 2. Prompt设计

上面示例中，直接让基座模型进行信息的抽取，是一种 **ZERO-SHOT** 的策略，当然我们也可以通过在 Prompt 中给定一些范例，以达到 **ONE/FEW-SHOT** 的策略，但不一定能够提高模型识别的准确率。

> 此外，如果我们喂给大模型的文本内容过多，很容易会导致信息不准确率，通过适当地定位到包含信息的语料块，也可以大幅提高大模型对于实体信息的识别准确率。
{style="note"}

### 2.1 实体识别Prompt



## 3.文章总结

[LLM Base NER, 大模型在命名实体识别的应用](https://zhuanlan.zhihu.com/p/657982188) 这篇文章对如何通过大模型完成实体命名识别任务做了详细的说明，其主要参考资料来源于一些综述和论文，有兴趣的同学可以花时间阅读一下该篇文章。

> 文章中提及不同查询方式下 LLM 的效果排序如下，**显然识别多实体信息要远单个实体** ：
> 
> 1. 一次查询一个实体类型
> 2. 使用 ChatGPT 生成描述词语作为实体类型名称进行查询
> 3. 一次查询所有实体类型


![消融试验](https://pic2.zhimg.com/80/v2-81edc405bae74ab9edbd168a081c77ed_720w.webp)


<seealso>
<category ref="ref_github">
    <a href="https://github.com/THUDM/ChatGLM-6B">ChatGLM信息抽取</a>
</category>
<category ref="ref_docs">
    <a href="https://zhuanlan.zhihu.com/p/657982188">🔥大模型在命名实体识别的应用</a>
</category>
</seealso>



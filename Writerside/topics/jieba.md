# Jieba 教程

<show-structure depth="3"/>

在自然语言处理（NLP）领域，中文文本的分词是一个重要且基础的任务。Python的jieba库是一个广泛使用的中文分词工具，提供了丰富的功能，包括精准模式、全模式、搜索引擎模式等，适用于不同的应用场景。本文将详细介绍jieba库，包括其安装方法、主要特性、基本和高级功能，以及实际应用场景，帮助全面了解并掌握该库的使用。



<seealso>
<category ref="ref_docs">
    <a href="https://mp.weixin.qq.com/s/o2jdWutOzNVTLbGWFU_Fqw">强大的 Python 库: Jieba</a>
</category>
<category ref="ref_github">
    <a href="https://github.com/fxsjy/jieba">Jieba</a>
</category>
<category ref="ref_issues">
</category>
<category ref="ref_hf">
</category>
<category ref="ref_ms">
</category>
</seealso>

